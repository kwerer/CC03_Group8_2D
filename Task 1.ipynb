{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions from cohort and homework week 9\n",
    "\n",
    "def normalize_z(df):\n",
    "    return ((df - df.mean(axis=0))/df.std(axis=0))\n",
    "\n",
    "def get_features_targets(df, feature_names, target_names):\n",
    "    # get df of selected features\n",
    "    df_feature = df[feature_names]\n",
    "    # get df of selected targets\n",
    "    df_target = df[target_names]\n",
    "    return df_feature, df_target\n",
    "\n",
    "def prepare_feature(df_feature):\n",
    "    # number of columns in the dataframe\n",
    "    cols = len(df_feature.columns)\n",
    "    # convert df to numpy\n",
    "    feature = df_feature.to_numpy().reshape(-1,cols)\n",
    "    array = np.concatenate((np.ones((feature.shape[0],1)), feature), axis = 1)\n",
    "    return array\n",
    "\n",
    "def prepare_target(df_target):\n",
    "    cols = len(df_target.columns)\n",
    "    target = df_target.to_numpy().reshape(-1,cols)\n",
    "    return target\n",
    "\n",
    "def predict(df_feature, beta):\n",
    "    df_feature = normalize_z(df_feature)\n",
    "    preped_feature = prepare_feature(df_feature)\n",
    "    return predict_norm(preped_feature, beta)\n",
    "\n",
    "def predict_norm(X, beta):\n",
    "    display(X.shape, \"x shape\")\n",
    "    display(beta.shape, \"beta shape\")\n",
    "    return np.matmul(X,beta)\n",
    "\n",
    "def split_data(df_feature, df_target, random_state=100, test_size=0.3):\n",
    "    indexes = df_feature.index\n",
    "    if random_state != None:\n",
    "        np.random.seed(random_state)\n",
    "    k = int(test_size * len(indexes))\n",
    "    test_index = np.random.choice(indexes, k, replace=False)\n",
    "    indexes = set(indexes)\n",
    "    test_index = set(test_index)\n",
    "    train_index = indexes - test_index\n",
    "    # the above indexes just helps you to get random indexes within the entire data\n",
    "    df_feature_train = df_feature.loc[train_index, :]\n",
    "    df_feature_test = df_feature.loc[test_index, :]\n",
    "    df_target_train = df_target.loc[train_index, :]\n",
    "    df_target_test = df_target.loc[test_index, :]\n",
    "    \n",
    "    return df_feature_train, df_feature_test, df_target_train, df_target_test\n",
    "  \n",
    "def r2_score(y, ypred):\n",
    "    ss_res = np.sum((y-ypred)**2)\n",
    "    y_mean = np.mean(y)\n",
    "    ss_tot = np.sum((y-y_mean)**2)\n",
    "    r_2 = (1-(ss_res/ss_tot))\n",
    "    return r_2\n",
    "\n",
    "def mean_squared_error(target, pred):\n",
    "    num_data = target.shape[0]\n",
    "    return (1/num_data)*(np.sum((target-pred)**2))\n",
    "\n",
    "def mean_absolute_error(target,pred):\n",
    "    num_data = target.shape[0]\n",
    "    return (1/num_data)*(abs(np.sum(target-pred)))\n",
    "\n",
    "def compute_cost(X, y, beta): #beta is weighted values, in this case it is just choosen from random values\n",
    "    J = 0\n",
    "    number_of_samples = X.shape[0]\n",
    "    error = np.matmul(X, beta) - y\n",
    "    error_sq = np.matmul(error.T, error)\n",
    "    J = (1)/(2*number_of_samples) * error_sq \n",
    "    J = J[0][0]\n",
    "    return J\n",
    "\n",
    "def gradient_descent(X, y, beta, alpha, num_iters):\n",
    "    number_of_samples = X.shape[0]\n",
    "    J_storage = []\n",
    "    for i in range(num_iters):\n",
    "        derivative_error = (1/(number_of_samples)) * np.matmul(X.T, (np.matmul(X, beta) - y))\n",
    "        beta = beta - alpha *  derivative_error\n",
    "        J_storage.append(compute_cost(X, y, beta))\n",
    "    return beta, J_storage\n",
    "\n",
    "# single function to make the model\n",
    "# @args\n",
    "# 1. alpha-value (step for gradient descent)\n",
    "# 2. beta (starting beta values for gradient descent)\n",
    "# 3. iterations (number of iterations of gradient descent)\n",
    "# 4. start (starting row)\n",
    "# 5. end (last row)\n",
    "# 6. feature_parameters (features used to train model)\n",
    "# @return r^2 and mse values + mae value\n",
    "\n",
    "def make_model_vs_excel(alpha, beta, iterations,start=None,end=None, feature_parameters = [\"total_cases\",\"new_cases\",\"new_cases_smoothed\",\"total_cases_per_million\",\"new_cases_per_million\",\"new_cases_smoothed_per_million\",\"reproduction_rate\"], dataset = \"Data/Task 1/countries_covid_data_total_features.csv\" , target_column = [\"new_deaths_smoothed\"]):\n",
    "    df = pd.read_csv(dataset)\n",
    "    \n",
    "    # Extract the features and the target\n",
    "    df_features_original_train, df_target = get_features_targets(df.loc[start:end,:],feature_parameters,target_column)\n",
    "\n",
    "    # # Split the data set into training and test\n",
    "    # df_features_train, df_features_test, df_target_train, df_target_test = split_data(df_features_original_train,df_target,100,0.3)\n",
    "\n",
    "    # Normalize the features using z normalization\n",
    "    df_features_train_z = normalize_z(df_features_original_train)\n",
    "\n",
    "    # Change the features and the target to numpy array using the prepare functions\n",
    "    X = prepare_feature(df_features_train_z)\n",
    "    target = prepare_target(df_target)\n",
    "\n",
    "    # Call the gradient_descent function\n",
    "    print(X.shape)\n",
    "    print(beta.shape)\n",
    "    print(target.shape)\n",
    "    beta, J_storage = gradient_descent(X, target, beta, alpha, iterations)\n",
    "\n",
    "\n",
    "    # call the predict() method\n",
    "    pred = predict(df_features_original_train,beta)\n",
    "\n",
    "    target = prepare_target(df_target)\n",
    "    r2 = r2_score(target,pred)\n",
    "    mse = mean_squared_error(target, pred)\n",
    "    mae = mean_absolute_error(target, pred)\n",
    "    print(f\"r^2 value = {r2}, mean squared error = {mse}, mean absolute error = {mae}\")\n",
    "    return r2, mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 8)\n",
      "(8, 1)\n",
      "(70, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(70, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'x shape'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(8, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'beta shape'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r^2 value = 0.7294264763291036, mean squared error = 215.8459764990375, mean absolute error = 1.7337242752546444e-13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7294264763291036, 215.8459764990375, 1.7337242752546444e-13)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_model_vs_excel(0.01, np.zeros((8,1)),3300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a44b83bb1c3a6304927ca6da078b6e1f296a39d2bf964431490b8ee2e0333e4a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
